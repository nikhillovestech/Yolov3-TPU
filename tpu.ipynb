{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "slim = tf.contrib.slim\n",
    "\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import collections\n",
    "import re\n",
    "import functools\n",
    "\n",
    "from tensorflow.python import pywrap_tensorflow\n",
    "from tensorflow.python.framework import constant_op\n",
    "from tensorflow.python.ops import array_ops, image_ops\n",
    "\n",
    "from tensorflow.contrib.cluster_resolver import TPUClusterResolver\n",
    "from tensorflow.contrib import tpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hparams():\n",
    "    hparams = tf.contrib.training.HParams(\n",
    "        fine_tune = True,\n",
    "        channels=3,\n",
    "        use_tpu = True,\n",
    "        ignore_thresh=0.7,\n",
    "        num_train_images=6944,\n",
    "        anchors = np.array([[10, 13], [16, 30], [33, 23],\n",
    "                        [30, 61], [62, 45], [59,  119],\n",
    "                        [116, 90], [156, 198], [373,326]], dtype=np.float32),\n",
    "        \n",
    "        input_shape = (416, 416),\n",
    "        train_batch_size= 32 * 8,\n",
    "        #batch_size = 32 * 8,\n",
    "        shuffle = 32*8,\n",
    "        width = 416,\n",
    "        height = 416,\n",
    "        train = tf.estimator.ModeKeys.TRAIN,\n",
    "        num_class = 1,\n",
    "        train_tfrecord = 'gs://{}/{}/{}'.format('neuron', 'data', 'OID_train.tfrecords'),#'bucket/data/OID_train.tfrecords',\n",
    "        init_checkpoint = 'gs://{}/{}/{}'.format('neuron', 'data', 'yolo_checkpoint.ckpt'),#'bucket/data/yolo_checkpoint.ckpt',\n",
    "        model_dir = 'gs://{}/{}'.format('neuron', 'checkpoints'),\n",
    "        restore_part = ['yolov3/darknet53_body'],\n",
    "        update_part = ['yolov3/yolov3_head'],\n",
    "        save_vars = ['yolov3'],\n",
    "        num_examples = 6944,\n",
    "        iteration_per_loop = 100,\n",
    "        base_learning_rate = 1e-1,\n",
    "        decay_rate = 0.5,\n",
    "        decay_steps = 250,\n",
    "        num_cores = 8,\n",
    "        num_cores_per_replica = 8,\n",
    "        num_epochs = 50,\n",
    "        tpu_zone = 'us-central1-c',\n",
    "        #tpu = 'grpc://10.0.4.2:8470',\n",
    "        tpu = 'grpc://10.0.101.2:8470',\n",
    "        gcp_project = 'fluted-visitor-233103'\n",
    "    )\n",
    "    \n",
    "    return hparams\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(inputs, filters, kernel_size, strides=1):\n",
    "    def _fixed_padding(inputs, kernel_size):\n",
    "        pad_total = kernel_size - 1\n",
    "        pad_beg = pad_total // 2\n",
    "        pad_end = pad_total - pad_beg\n",
    "\n",
    "        padded_inputs = tf.pad(inputs, [[0, 0], [pad_beg, pad_end],\n",
    "                                        [pad_beg, pad_end], [0, 0]], mode='CONSTANT')\n",
    "        return padded_inputs\n",
    "    if strides > 1: \n",
    "        inputs = _fixed_padding(inputs, kernel_size)\n",
    "    inputs = slim.conv2d(inputs, filters, kernel_size, stride=strides,\n",
    "                         padding=('SAME' if strides == 1 else 'VALID'))\n",
    "    return inputs\n",
    "\n",
    "def darknet53_body(inputs):\n",
    "    def res_block(inputs, filters):\n",
    "        shortcut = inputs\n",
    "        net = conv2d(inputs, filters * 1, 1)\n",
    "        net = conv2d(net, filters * 2, 3)\n",
    "\n",
    "        net = net + shortcut\n",
    "\n",
    "        return net\n",
    "    \n",
    "    # first two conv2d layers\n",
    "    net = conv2d(inputs, 32,  3, strides=1)\n",
    "    net = conv2d(net, 64,  3, strides=2)\n",
    "\n",
    "    # res_block * 1\n",
    "    net = res_block(net, 32)\n",
    "\n",
    "    net = conv2d(net, 128, 3, strides=2)\n",
    "\n",
    "    # res_block * 2\n",
    "    for i in range(2):\n",
    "        net = res_block(net, 64)\n",
    "\n",
    "    net = conv2d(net, 256, 3, strides=2)\n",
    "\n",
    "    # res_block * 8\n",
    "    for i in range(8):\n",
    "        net = res_block(net, 128)\n",
    "\n",
    "    route_1 = net\n",
    "    net = conv2d(net, 512, 3, strides=2)\n",
    "\n",
    "    # res_block * 8\n",
    "    for i in range(8):\n",
    "        net = res_block(net, 256)\n",
    "\n",
    "    route_2 = net\n",
    "    net = conv2d(net, 1024, 3, strides=2)\n",
    "\n",
    "    # res_block * 4\n",
    "    for i in range(4):\n",
    "        net = res_block(net, 512)\n",
    "    route_3 = net\n",
    "\n",
    "    return route_1, route_2, route_3\n",
    "\n",
    "\n",
    "def yolo_block(inputs, filters):\n",
    "    net = conv2d(inputs, filters * 1, 1)\n",
    "    net = conv2d(net, filters * 2, 3)\n",
    "    net = conv2d(net, filters * 1, 1)\n",
    "    net = conv2d(net, filters * 2, 3)\n",
    "    net = conv2d(net, filters * 1, 1)\n",
    "    route = net\n",
    "    net = conv2d(net, filters * 2, 3)\n",
    "    return route, net\n",
    "\n",
    "\n",
    "def upsample_layer(inputs, out_shape):\n",
    "    new_height, new_width = out_shape[1], out_shape[2]\n",
    "    # NOTE: here height is the first\n",
    "    inputs = tf.image.resize_nearest_neighbor(inputs, (new_height, new_width), align_corners=True, name='upsampled')\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def int_shape(x):\n",
    "    if hasattr(x, '_keras_shape'):\n",
    "      return x._keras_shape\n",
    "    try:\n",
    "      return tuple(x.get_shape().as_list())\n",
    "    except ValueError:\n",
    "      return None\n",
    "  \n",
    "def resize_images(x):\n",
    "    \n",
    "    height_factor = 2\n",
    "    width_factor = 2\n",
    "    data_format = 'channels_last'\n",
    "  \n",
    "    if data_format == 'channels_first':\n",
    "      rows, cols = 2, 3\n",
    "    elif data_format == 'channels_last':\n",
    "      rows, cols = 1, 2\n",
    "    else:\n",
    "      raise ValueError('Invalid `data_format` argument: %s' % (data_format,))\n",
    "\n",
    "    original_shape = int_shape(x)\n",
    "    new_shape = array_ops.shape(x)[rows:cols + 1]\n",
    "    new_shape *= constant_op.constant(\n",
    "        np.array([height_factor, width_factor], dtype='int32'))\n",
    "\n",
    "    x = image_ops.resize_bilinear(x, new_shape, align_corners=True, name='upsample')\n",
    "\n",
    "\n",
    "    if original_shape[rows] is None:\n",
    "      new_height = None\n",
    "    else:\n",
    "      new_height = original_shape[rows] * height_factor\n",
    "\n",
    "    if original_shape[cols] is None:\n",
    "      new_width = None\n",
    "    else:\n",
    "      new_width = original_shape[cols] * width_factor\n",
    "\n",
    "    if data_format == 'channels_first':\n",
    "      output_shape = (None, None, new_height, new_width)\n",
    "    else:\n",
    "      output_shape = (None, new_height, new_width, None)\n",
    "    x.set_shape(output_shape)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_assignment_map_from_checkpoint(tvars, init_checkpoint):\n",
    "    \n",
    "    assignment_map = {}\n",
    "    initialized_variable_names = {}\n",
    "    \n",
    "    name_to_variable = collections.OrderedDict()\n",
    "    '''for var in tvars:\n",
    "        name = var.name\n",
    "        m = re.match('^(.*):\\\\d+$', name)\n",
    "        if m is not None:\n",
    "            name = m.group(1)\n",
    "        name_to_variable[name] = name'''\n",
    "    \n",
    "    for var in tvars:\n",
    "        name_to_variable[var] = var\n",
    "        \n",
    "    init_vars = tf.train.list_variables(init_checkpoint)\n",
    "    \n",
    "    assignment_map = collections.OrderedDict()\n",
    "    for x in init_vars:\n",
    "        (name, var) = (x[0], x[1])\n",
    "        if name not in name_to_variable:\n",
    "            continue\n",
    "            \n",
    "        assignment_map[name] = name\n",
    "        initialized_variable_names[name] = 1\n",
    "        initialized_variable_names[name+\":0\"] = 1\n",
    "        \n",
    "    return assignment_map, initialized_variable_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class yolov3(object):\n",
    "\n",
    "    def __init__(self, params, batch_norm_decay=0.9):\n",
    "\n",
    "        self.anchors = params['anchors']\n",
    "        self.class_num = params['num_class']\n",
    "        #self.anchors = anchors\n",
    "        self.batch_norm_decay = batch_norm_decay\n",
    "\n",
    "    def forward(self, inputs, is_training=False, reuse=False):\n",
    "        # the input img_size, form: [height, weight]\n",
    "        # it will be used later\n",
    "        #print(inputs)\n",
    "        self.img_size = tf.shape(inputs)[1:3]\n",
    "        # set batch norm params\n",
    "        batch_norm_params = {\n",
    "            'decay': self.batch_norm_decay,\n",
    "            'epsilon': 1e-05,\n",
    "            'scale': True,\n",
    "            'is_training': is_training,\n",
    "            'fused': None,  # Use fused batch norm if possible.\n",
    "        }\n",
    "        \n",
    "        #with graph.as_default():\n",
    "   \n",
    "        with slim.arg_scope([slim.conv2d, slim.batch_norm],reuse=reuse):\n",
    "          with slim.arg_scope([slim.conv2d], normalizer_fn=slim.batch_norm,\n",
    "                              normalizer_params=batch_norm_params,\n",
    "                              biases_initializer=None,\n",
    "                              activation_fn=lambda x: tf.nn.leaky_relu(x, alpha=0.1)):\n",
    "              with tf.variable_scope('yolov3/darknet53_body'):\n",
    "                  route_1, route_2, route_3 = darknet53_body(inputs)\n",
    "\n",
    "              with tf.variable_scope('yolov3/yolov3_head'):\n",
    "                  inter1, net = yolo_block(route_3, 512)\n",
    "                  feature_map_1 = slim.conv2d(net, 3 * (5 + self.class_num), 1,\n",
    "                                              stride=1, normalizer_fn=None,\n",
    "                                              activation_fn=None, biases_initializer=tf.zeros_initializer())\n",
    "                  feature_map_1 = tf.identity(feature_map_1, name='feature_map_1')\n",
    "\n",
    "                  #print(feature_map_1)\n",
    "                  inter1 = conv2d(inter1, 256, 1)\n",
    "                  inter1 = resize_images(inter1)\n",
    "                  concat1 = tf.concat([inter1, route_2], axis=3)\n",
    "                  #print(inter1)\n",
    "\n",
    "                  inter2, net = yolo_block(concat1, 256)\n",
    "                  feature_map_2 = slim.conv2d(net, 3 * (5 + self.class_num), 1,\n",
    "                                              stride=1, normalizer_fn=None,\n",
    "                                              activation_fn=None, biases_initializer=tf.zeros_initializer())\n",
    "                  feature_map_2 = tf.identity(feature_map_2, name='feature_map_2')\n",
    "                  #print(feature_map_2)\n",
    "\n",
    "                  inter2 = conv2d(inter2, 128, 1)\n",
    "                  inter2 = resize_images(inter2)\n",
    "                  concat2 = tf.concat([inter2, route_1], axis=3)\n",
    "                  #print(inter2)\n",
    "\n",
    "                  _, feature_map_3 = yolo_block(concat2, 128)\n",
    "                  feature_map_3 = slim.conv2d(feature_map_3, 3 * (5 + self.class_num), 1,\n",
    "                                              stride=1, normalizer_fn=None,\n",
    "                                              activation_fn=None, biases_initializer=tf.zeros_initializer())\n",
    "                  feature_map_3 = tf.identity(feature_map_3, name='feature_map_3')\n",
    "\n",
    "          return feature_map_1, feature_map_2, feature_map_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadcast_iou(true_box_xy, true_box_wh, pred_box_xy, pred_box_wh):\n",
    "  \n",
    "        \n",
    "        #print(pred_box_xy.shape, pred_box_wh.shape)\n",
    "        #print(true_box_xy.shape, true_box_wh.shape)\n",
    "    \n",
    "        pred_box_xy = tf.expand_dims(pred_box_xy, -2)\n",
    "        pred_box_wh = tf.expand_dims(pred_box_wh, -2)\n",
    "      \n",
    "        true_box_xy = tf.expand_dims(true_box_xy, 0)\n",
    "        true_box_wh = tf.expand_dims(true_box_wh, 0)\n",
    "        \n",
    "        #print(pred_box_xy.shape, pred_box_wh.shape)\n",
    "        #print(true_box_xy.shape, true_box_wh.shape)\n",
    "        \n",
    "        intersect_mins = tf.maximum(pred_box_xy - pred_box_wh / 2.,\n",
    "                                    true_box_xy - true_box_wh / 2.)\n",
    "        \n",
    "        intersect_maxs = tf.minimum(pred_box_xy + pred_box_wh / 2.,\n",
    "                                    true_box_xy + true_box_wh / 2.)\n",
    "        \n",
    "        intersect_wh = tf.maximum(intersect_maxs - intersect_mins, 0.)\n",
    "        \n",
    "        intersect_area = intersect_wh[..., 0] * intersect_mins[..., 1]\n",
    "        pred_box_area = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n",
    "        true_box_area = true_box_wh[..., 0] * true_box_wh[..., 1]\n",
    "        \n",
    "        iou = intersect_area / (pred_box_area + true_box_area - intersect_area + 1e-10)\n",
    "        \n",
    "        \n",
    "        return iou\n",
    "\n",
    "def _reorg_layer(feature_map, anchors, num_classes, img_size):\n",
    "\n",
    "        num_anchors = len(anchors) # num_anchors=3\n",
    "        # grid_size = tf.shape(feature_map)[1:3]\n",
    "        grid_size = feature_map.shape.as_list()[1:3]\n",
    "\n",
    "        stride = tf.cast(img_size // grid_size, tf.float32)\n",
    "        anchors = [(a[0] / stride[0], a[1] / stride[1]) for a in anchors]\n",
    "\n",
    "        feature_map = tf.reshape(feature_map, [-1, grid_size[0], grid_size[1], num_anchors, 5 + num_classes])\n",
    "\n",
    "        box_centers, box_sizes, conf_logits, prob_logits = tf.split(\n",
    "            feature_map, [2, 2, 1, num_classes], axis=-1)\n",
    "\n",
    "        box_centers = tf.nn.sigmoid(box_centers)\n",
    "\n",
    "        grid_x = tf.range(grid_size[0], dtype=tf.int32)\n",
    "        grid_y = tf.range(grid_size[1], dtype=tf.int32)\n",
    "\n",
    "        a, b = tf.meshgrid(grid_x, grid_y)\n",
    "        x_offset = tf.reshape(a, (-1, 1))\n",
    "        y_offset = tf.reshape(b, (-1, 1))\n",
    "        x_y_offset = tf.concat([x_offset, y_offset], axis=-1)\n",
    "        x_y_offset = tf.reshape(x_y_offset, [grid_size[0], grid_size[1], 1, 2])\n",
    "        x_y_offset = tf.cast(x_y_offset, tf.float32)\n",
    "\n",
    "        box_centers = box_centers + x_y_offset\n",
    "        box_centers = box_centers * stride[::-1]\n",
    "\n",
    "        box_sizes = tf.clip_by_value(tf.exp(box_sizes), 1e-9, 50) * anchors\n",
    "        box_sizes = box_sizes * stride[::-1]\n",
    "\n",
    "        boxes = tf.concat([box_centers, box_sizes], axis=-1)\n",
    "        return x_y_offset, boxes, conf_logits, prob_logits\n",
    "      \n",
    "def loss_layer(feature_map_i, y_true, anchors, num_classes, img, ignore_thresh):\n",
    "\n",
    "        NO_OBJECT_SCALE  = 1.0\n",
    "        OBJECT_SCALE     = 5.0\n",
    "        COORD_SCALE      = 1.0\n",
    "        CLASS_SCALE      = 1.0\n",
    "\n",
    "        img_size = tf.shape(img)[1:3]\n",
    "        grid_size = tf.shape(feature_map_i)[1:3]\n",
    "        grid_size_ = feature_map_i.shape.as_list()[1:3]\n",
    "\n",
    "        y_true = tf.reshape(y_true, [-1, grid_size_[0], grid_size_[1], 3, 5+num_classes])\n",
    "        stride = tf.cast(img_size//grid_size, dtype=tf.float32)\n",
    "        N = tf.cast(tf.shape(feature_map_i)[0], tf.float32)\n",
    "\n",
    "        pred_result = _reorg_layer(feature_map_i, anchors, num_classes, img_size)\n",
    "        x_y_offset,  pred_boxes, pred_conf_logits, pred_prob_logits = pred_result\n",
    "\n",
    "        object_mask = y_true[..., 4:5]\n",
    "        \n",
    "        '''valid_true_boxes = tf.boolean_mask(y_true[..., 0:4], tf.cast(object_mask[..., 0], 'bool'))\n",
    "        #print(valid_true_boxes.shape)\n",
    "        valid_true_box_xy = valid_true_boxes[:, 0:2]\n",
    "        valid_true_box_wh = valid_true_boxes[:, 2:4]\n",
    "        \n",
    "        pred_box_xy = pred_boxes[..., 0:2]\n",
    "        pred_box_wh = pred_boxes[..., 2:4]\n",
    "        \n",
    "        iou = broadcast_iou(valid_true_box_xy, valid_true_box_wh, pred_box_xy, pred_box_wh)\n",
    "        \n",
    "        best_iou = tf.reduce_max(iou, axis=-1)\n",
    "        \n",
    "        ignore_mask = tf.cast(best_iou < 0.5, tf.float32)\n",
    "        ignore_mask = tf.expand_dims(ignore_mask, -1)\n",
    "        \n",
    "        true_xy = y_true[..., 0:2] / stride[::-1] - x_y_offset\n",
    "        pred_xy = pred_box_xy / stride[::-1] - x_y_offset\n",
    "        \n",
    "        true_tw_th = y_true[..., 2:4] / anchors\n",
    "        pred_tw_th = pred_box_wh / anchors\n",
    "        \n",
    "        true_tw_th = tf.where(condition=tf.equal(true_tw_th, 0), x=tf.ones_like(true_tw_th), y=true_tw_th)\n",
    "        pred_tw_th = tf.where(condition=tf.equal(pred_tw_th, 0), x=tf.ones_like(pred_tw_th), y=pred_tw_th)\n",
    "        \n",
    "        true_box_conf = y_true[...,4:5]\n",
    "        pred_box_conf = tf.sigmoid(pred_conf_logits)\n",
    "        \n",
    "        conf_mask = ignore_mask * (1 - object_mask) * NO_OBJECT_SCALE\n",
    "        # penalize the confidence of the boxes, which are reponsible for corresponding ground truth box\n",
    "        conf_mask = conf_mask + object_mask * OBJECT_SCALE\n",
    "\n",
    "        ### adjust class probabilities\n",
    "        class_mask = object_mask * CLASS_SCALE\n",
    "        nb_conf_box  = tf.reduce_sum(tf.to_float(conf_mask  > 0.0))\n",
    "        nb_class_box = tf.reduce_sum(tf.to_float(class_mask > 0.0))\n",
    "\n",
    "        \n",
    "        true_tw_th = tf.log(tf.clip_by_value(true_tw_th, 1e-9, 1e9))\n",
    "        pred_tw_th = tf.log(tf.clip_by_value(pred_tw_th, 1e-9, 1e9))\n",
    "        \n",
    "        box_loss_scale = 2. - (y_true[..., 2:3] / tf.cast(img_size[1], tf.float32)) * (y_true[..., 3:4] / tf.cast(img_size[0], tf.float32))\n",
    "        \n",
    "        xy_loss = tf.reduce_sum(tf.square(true_xy - pred_xy) * object_mask* box_loss_scale) / N\n",
    "        wh_loss = tf.reduce_sum(tf.square(true_tw_th - pred_tw_th) * object_mask ) / N\n",
    "        \n",
    "        conf_loss = tf.reduce_sum(tf.square(true_box_conf-pred_box_conf) * conf_mask)  / (nb_conf_box  + 1e-6) / N\n",
    "        class_loss = object_mask * tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true[..., 5:], logits=pred_prob_logits)\n",
    "        class_loss = tf.reduce_sum(class_loss) / N'''\n",
    "        #loss_class = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true[...,5:], logits=pred_prob_logits)\n",
    "        #class_loss = tf.reduce_sum(loss_class * class_mask) / (nb_class_box + 1e-6) / 2.\n",
    "        \n",
    "        '''conf_pos_mask = object_mask\n",
    "        conf_neg_mask = (1 - object_mask) * ignore_mask\n",
    "        conf_loss_pos = conf_pos_mask * tf.nn.sigmoid_cross_entropy_with_logits(labels=object_mask, logits=pred_conf_logits)\n",
    "        conf_loss_neg = conf_neg_mask * tf.nn.sigmoid_cross_entropy_with_logits(labels=object_mask, logits=pred_conf_logits)\n",
    "        \n",
    "        conf_loss = tf.reduce_sum(conf_loss_pos + conf_loss_neg) / N\n",
    "        \n",
    "        class_loss = object_mask * tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true[..., 5:], logits=pred_prob_logits)\n",
    "        class_loss = tf.reduce_sum(class_loss) / N'''\n",
    "        \n",
    "        \n",
    "        true_box_xy = y_true[...,:2] # absolute coordinate\n",
    "        true_box_wh = y_true[...,2:4] # absolute size\n",
    "\n",
    "        pred_box_xy = pred_boxes[...,:2]# absolute coordinate\n",
    "        pred_box_wh = pred_boxes[...,2:4]# absolute size\n",
    "\n",
    "        # caculate iou between true boxes and pred boxes\n",
    "        intersect_xy1 = tf.maximum(true_box_xy - true_box_wh / 2.0,\n",
    "                                   pred_box_xy - pred_box_wh / 2.0)\n",
    "        intersect_xy2 = tf.minimum(true_box_xy + true_box_wh / 2.0,\n",
    "                                   pred_box_xy + pred_box_wh / 2.0)\n",
    "        intersect_wh = tf.maximum(intersect_xy2 - intersect_xy1, 0.)\n",
    "        intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "\n",
    "        true_area = true_box_wh[..., 0] * true_box_wh[..., 1]\n",
    "        pred_area = pred_box_wh[..., 0] * pred_box_wh[..., 1]\n",
    "\n",
    "        union_area = true_area + pred_area - intersect_area + 1e-10\n",
    "        iou_scores = tf.truediv(intersect_area, union_area)\n",
    "        iou_scores = tf.expand_dims(iou_scores, axis=-1)\n",
    "\n",
    "        true_box_conf = y_true[...,4:5]\n",
    "        pred_box_conf = tf.sigmoid(pred_conf_logits)\n",
    "        ### adjust x and y => relative position to the containing cell\n",
    "        true_box_xy = true_box_xy / stride  - x_y_offset\n",
    "        pred_box_xy = pred_box_xy / stride  - x_y_offset\n",
    "\n",
    "        ### adjust w and h => relative size to the containing cell\n",
    "        true_box_wh_logit = true_box_wh / (anchors * stride)\n",
    "        pred_box_wh_logit = pred_box_wh / (anchors * stride)\n",
    "\n",
    "        true_box_wh_logit = tf.where(condition=tf.equal(true_box_wh_logit,0),\n",
    "                                     x=tf.ones_like(true_box_wh_logit), y=true_box_wh_logit)\n",
    "        pred_box_wh_logit = tf.where(condition=tf.equal(pred_box_wh_logit,0),\n",
    "                                     x=tf.ones_like(pred_box_wh_logit), y=pred_box_wh_logit)\n",
    "\n",
    "        true_box_wh = tf.log(tf.clip_by_value(true_box_wh_logit, 1e-9, 1e9))\n",
    "        pred_box_wh = tf.log(tf.clip_by_value(pred_box_wh_logit, 1e-9, 1e9))\n",
    "        #if not np.isnan(true_box_wh) and not np.isnan(pred_box_wh):\n",
    "          \n",
    "\n",
    "        \n",
    "        conf_mask = tf.cast(iou_scores < ignore_thresh, dtype=tf.float32) * (1 - object_mask) * NO_OBJECT_SCALE\n",
    "        # penalize the confidence of the boxes, which are reponsible for corresponding ground truth box\n",
    "        conf_mask = conf_mask + object_mask * OBJECT_SCALE\n",
    "\n",
    "        ### adjust class probabilities\n",
    "        class_mask = object_mask * CLASS_SCALE\n",
    "        ### class mask: simply the position of the ground truth boxes (the predictors)\n",
    "        coord_mask = object_mask * COORD_SCALE\n",
    "\n",
    "        nb_coord_box = tf.reduce_sum(tf.cast(coord_mask > 0.0, dtype=tf.float32))\n",
    "        nb_conf_box  = tf.reduce_sum(tf.cast(conf_mask  > 0.0, dtype=tf.float32))\n",
    "        nb_class_box = tf.reduce_sum(tf.cast(class_mask > 0.0, dtype=tf.float32))\n",
    "\n",
    "        xy_loss = tf.reduce_sum(tf.square(true_box_xy-pred_box_xy)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "        #xy_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels = true_box_xy, logits = pred_box_xy) * coord_mask / (nb_coord_box + 1e-6) / 2.\n",
    "        wh_loss = tf.reduce_sum(tf.square(true_box_wh-pred_box_wh)     * coord_mask) / (nb_coord_box + 1e-6) / 2.\n",
    "        conf_loss = tf.reduce_sum(tf.square(true_box_conf-pred_box_conf) * conf_mask)  / (nb_conf_box  + 1e-6) / 2.\n",
    "        loss_class = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true[...,5:], logits=pred_prob_logits)\n",
    "        loss_class = tf.clip_by_value(loss_class, 1e-4, 10)\n",
    "        class_loss = tf.reduce_sum(loss_class * class_mask) / (nb_class_box + 1e-6) / N\n",
    "\n",
    "        return xy_loss, wh_loss, conf_loss, class_loss\n",
    "      \n",
    "def compute_loss(y_pred, y_true, anchors, num_classes, img, ignore_thresh):\n",
    "        \"\"\"\n",
    "        Note: compute the loss\n",
    "        Arguments: y_pred, list -> [feature_map_1, feature_map_2, feature_map_3]\n",
    "                                        the shape of [None, 13, 13, 3*85]. etc\n",
    "        \"\"\"\n",
    "        loss_coord, loss_sizes, loss_confs, loss_class = 0., 0., 0., 0.\n",
    "        _ANCHORS = [anchors[6:9], anchors[3:6], anchors[0:3]]\n",
    "        y_true = [y_true['y_true1'], y_true['y_true2'], y_true['y_true3']]\n",
    "        \n",
    "        #iou = []\n",
    "        for i in range(len( y_pred )):\n",
    "            result = loss_layer(y_pred[i], y_true[i], _ANCHORS[i], num_classes, img, ignore_thresh)\n",
    "            loss_coord       += result[0]\n",
    "            loss_sizes       += result[1]\n",
    "            loss_confs       += result[2]\n",
    "            loss_class       += result[3]\n",
    "            #iou.append(result[4])\n",
    "            \n",
    "        #l2_loss = tf.add_n([tf.nn.l2_loss(v) for v in tf.trainable_variables()])*0.001\n",
    "        total_loss = loss_coord + loss_sizes + loss_confs +  loss_class\n",
    "        #total_loss = tf.reduce_mean(total_loss)\n",
    "        return [total_loss, loss_coord, loss_sizes, loss_confs, loss_class]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_head(feats, anchors, num_classes, input_shape, training=True):\n",
    "  \n",
    "  num_anchors = len(anchors)\n",
    "  anchors_tensor = tf.reshape(tf.constant(anchors, dtype=tf.float32), [1, 1, 1, num_anchors, 2])\n",
    "  grid_size = tf.shape(feats)[1:3]\n",
    "  predictions = tf.reshape(feats, [-1, grid_size[0], grid_size[1], num_anchors, num_classes + 5])\n",
    "  \n",
    "  grid_y = tf.tile(tf.reshape(tf.range(grid_size[0]), [-1, 1, 1, 1]), [1, grid_size[1], 1, 1])\n",
    "  grid_x = tf.tile(tf.reshape(tf.range(grid_size[1]), [1, -1, 1, 1]), [grid_size[0], 1, 1, 1])\n",
    "  #print(grid_x.dtype)\n",
    "  #print(grid_y.dtype)\n",
    "  grid = tf.concat([grid_x, grid_y], axis=-1)\n",
    "  grid = tf.cast(grid, dtype=tf.float32)\n",
    "  \n",
    "  box_xy = (tf.sigmoid(predictions[..., :2]) + grid) / tf.cast(grid_size[::-1], tf.float32)\n",
    "  box_wh = tf.exp(predictions[..., 2:4]) * anchors_tensor / input_shape[::-1]\n",
    "  \n",
    "  box_confidence = tf.sigmoid(predictions[..., 4:5])\n",
    "  box_class_probs = tf.sigmoid(predictions[..., 5:])\n",
    "  \n",
    "  if training == True:\n",
    "    return grid, predictions, box_xy, box_wh\n",
    "  return box_xy, box_wh, box_confidence, box_class_probs\n",
    "\n",
    "\n",
    "def box_iou(box1, box2):\n",
    "  box1 = tf.expand_dims(box1, -2)\n",
    "  box1_xy = box1[..., :2]\n",
    "  box1_wh = box1[..., 2:4]\n",
    "  box1_mins = box1_xy - box1_wh / 2.\n",
    "  box1_maxs = box1_xy + box1_wh / 2.\n",
    "  \n",
    "  box2 = tf.expand_dims(box2, 0)\n",
    "  box2_xy = box2[..., :2]\n",
    "  box2_wh = box2[..., 2:4]\n",
    "  box2_mins = box2_xy - box2_wh / 2.\n",
    "  box2_maxs = box2_xy + box2_wh / 2.\n",
    "  \n",
    "  intersect_mins = tf.maximum(box1_mins, box2_mins)\n",
    "  intersect_maxs = tf.minimum(box1_maxs, box2_maxs)\n",
    "  intersect_wh = tf.maximum(intersect_maxs - intersect_mins, 0.)\n",
    "  intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "  \n",
    "  box1_area = box1_wh[..., 0] * box1_wh[..., 1]\n",
    "  box2_area = box2_wh[..., 0] * box2_wh[..., 1]\n",
    "  iou = intersect_area / (box1_area + box2_area - intersect_area + 1e-10)\n",
    "  return iou\n",
    "\n",
    "\n",
    "def yolo_loss(y_pred, y_true, anchors, num_classes, ignore_thresh):\n",
    "  \n",
    "    loss, xy_los, wh_los, confidence_los, class_los = 0, 0, 0, 0, 0\n",
    "    anchor_mask = [[6, 7, 8], [3, 4, 5], [0, 1, 2]]\n",
    "    input_shape = [416.0, 416.0]\n",
    "    grid_shapes = [tf.cast(tf.shape(y_pred[l])[1:3], tf.float32) for l in range(3)]\n",
    "    \n",
    "    y_true = [y_true['y_true1'], y_true['y_true2'], y_true['y_true3']]\n",
    "  \n",
    "    '''def sigmoid_cross_entropy(labels=None, logits=None):\n",
    "        #if labels is not None and logits is not None:\n",
    "        labels = tf.convert_to_tensor(labels)\n",
    "        logits = tf.convert_to_tensor(logits)\n",
    "        x = logits\n",
    "        z = labels\n",
    "        x1 = tf.where(tf.greater(x, 0), x=x, y=tf.zeros_like(x))\n",
    "\n",
    "        loss = x1 - x * z + tf.log(1+tf.exp(-abs(x)))\n",
    "        loss = tf.clip_by_value(loss, 1e-11, 1e9)\n",
    "\n",
    "        return loss'''\n",
    "\n",
    "    for i in range(3):\n",
    "        object_mask = y_true[i][..., 4:5]\n",
    "        #print(y_true[i])\n",
    "        class_probs = y_true[i][..., 5:]\n",
    "        grid, predictions, pred_xy, pred_wh = yolo_head(y_pred[i], anchors[anchor_mask[i]], num_classes, input_shape, training=True)\n",
    "\n",
    "        pred_box = tf.concat([pred_xy, pred_wh], axis=-1)\n",
    "        raw_true_xy = y_true[i][..., :2] * grid_shapes[i][::-1] - grid\n",
    "        object_mask_bool = (object_mask > 0)\n",
    "        raw_true_wh = tf.log(tf.where(tf.equal(y_true[i][..., 2:4] / anchors[anchor_mask[i]] * input_shape[::-1], 0), tf.ones_like(y_true[i][..., 2:4]), y_true[i][..., 2:4] / anchors[anchor_mask[i]] * input_shape[::-1]))\n",
    "        box_loss_scale = 2 - y_true[i][..., 2:3] * y_true[i][..., 3:4]\n",
    "        '''ignore_mask = tf.TensorArray(dtype=tf.float32, size = 1, dynamic_size = True)\n",
    "    \n",
    "        def loop_body(internal_index, ignore_mask):\n",
    "      \n",
    "            true_box = tf.boolean_mask(y_true[i][internal_index, ..., 0:4], object_mask_bool[internal_index, ..., 0])\n",
    "            iou = box_iou(pred_box[internal_index], true_box)\n",
    "            best_iou = tf.reduce_max(iou, axis=-1)\n",
    "            ignore_mask = ignore_mask.write(internal_index, tf.cast(best_iou < ignore_thresh, tf.float32))\n",
    "            return internal_index + 1, ignore_mask\n",
    "    \n",
    "        _, ignore_mask = tf.while_loop(lambda internal_index, ignore_mask : internal_index < tf.shape(y_pred[0])[0], loop_body, [0, ignore_mask])\n",
    "        ignore_mask = ignore_mask.stack()\n",
    "        ignore_mask = tf.expand_dims(ignore_mask, axis=-1)'''\n",
    "        \n",
    "      \n",
    "        #true_box = y_true[i][..., 0:4]\n",
    "        true_box = tf.boolean_mask(y_true[i][..., 0:4], object_mask_bool[..., 0])\n",
    "        #true_box = np.array(true_box, dtype=np.float32)\n",
    "        #true_box = true_box[object_mask_bool[..., 0]]\n",
    "        iou = box_iou(pred_box, true_box)\n",
    "        best_iou = tf.reduce_max(iou, axis=-1)\n",
    "        ignore_mask = tf.cast(best_iou < ignore_thresh, tf.float32)\n",
    "        ignore_mask = tf.expand_dims(ignore_mask, -1)\n",
    "\n",
    "\n",
    "        '''pred_box_xy = tf.where(condition=tf.equal(predictions[..., 0:2],0),\n",
    "                                         x=tf.ones_like(predictions[..., 0:2]), y=predictions[..., 0:2])\n",
    "        raw_true_xy = tf.where(condition=tf.equal(raw_true_xy,0),\n",
    "                                         x=tf.ones_like(raw_true_xy), y=raw_true_xy)'''\n",
    "\n",
    "\n",
    "\n",
    "        xy_loss =  object_mask * box_loss_scale * tf.nn.sigmoid_cross_entropy_with_logits(labels = raw_true_xy, logits = predictions[..., 0:2])\n",
    "        wh_loss = object_mask * box_loss_scale * 0.5 * tf.square(raw_true_wh - predictions[..., 2:4])\n",
    "        confidence_loss = object_mask * tf.nn.sigmoid_cross_entropy_with_logits(labels = object_mask, logits = predictions[..., 4:5]) + (1 - object_mask) * tf.nn.sigmoid_cross_entropy_with_logits(labels = object_mask, logits = predictions[..., 4:5]) * ignore_mask\n",
    "        class_loss = object_mask * tf.nn.sigmoid_cross_entropy_with_logits(labels = class_probs, logits = predictions[..., 5:])\n",
    "        xy_loss = tf.reduce_sum(xy_loss) / tf.cast(tf.shape(y_pred[0])[0], tf.float32)\n",
    "        wh_loss = tf.reduce_sum(wh_loss) / tf.cast(tf.shape(y_pred[0])[0], tf.float32)\n",
    "        confidence_loss = tf.reduce_sum(confidence_loss) / tf.cast(tf.shape(y_pred[0])[0], tf.float32)\n",
    "        class_loss = tf.reduce_sum(class_loss) / tf.cast(tf.shape(y_pred[0])[0], tf.float32)\n",
    "\n",
    "        xy_los += xy_loss\n",
    "        wh_los += wh_loss\n",
    "        confidence_los += confidence_loss\n",
    "        class_los += class_loss\n",
    "        loss += xy_loss + wh_loss + confidence_loss + class_loss\n",
    "\n",
    "    return [loss, xy_los, wh_los, confidence_los, class_los]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode, params):\n",
    "    \n",
    "    print('Model fn')\n",
    "    #print('features shape: ',features.shape)\n",
    "    #print('label: ',labels)\n",
    "    model = yolov3(params)\n",
    "    #with tf.variable_scope('yolov3'):\n",
    "    y_pred = model.forward(features, is_training=True)\n",
    "      \n",
    "    tvars = tf.trainable_variables()\n",
    "    vars_to_init = tf.contrib.framework.get_variables_to_restore(include=params['restore_part'])\n",
    "    initialized_variable_names = {}\n",
    "    \n",
    "    if params['init_checkpoint']:\n",
    "        (assignment_map, initialized_variable_names) = get_assignment_map_from_checkpoint(vars_to_init, params['init_checkpoint'])\n",
    "    \n",
    "    if mode == params['train']:\n",
    "        global_step = tf.train.get_or_create_global_step()\n",
    "        \n",
    "        update_vars = tf.contrib.framework.get_variables_to_restore(include=params['update_part'])\n",
    "        vars_to_save = tf.contrib.framework.get_variables_to_restore(include=params['save_vars'])\n",
    "        #loss = yolo_loss(y_pred, labels, params['anchors'], params['num_class'], params['ignore_thresh'])\n",
    "        loss = compute_loss(y_pred, labels, params['anchors'], params['num_class'], features, params['ignore_thresh'])\n",
    "        l2_loss = tf.losses.get_regularization_loss()\n",
    "        #loss[0] += l2_loss\n",
    "        total_loss = loss[0] + l2_loss\n",
    "        learning_rate = tf.train.exponential_decay(params['base_learning_rate'], global_step, params['decay_steps'], params['decay_rate'], staircase=True)\n",
    "        \n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "        \n",
    "        if params['use_tpu']:\n",
    "            optimizer = tf.contrib.tpu.CrossShardOptimizer(optimizer)\n",
    "        train_opt = optimizer.minimize(total_loss, global_step=global_step, var_list=update_vars)\n",
    "        \n",
    "        \n",
    "        if params['fine_tune']:\n",
    "            \n",
    "            def scaffold_fn():\n",
    "                tf.logging.info('Fine Tuning')\n",
    "                tf.train.init_from_checkpoint(params['init_checkpoint'], assignment_map)\n",
    "                #saver = tf.train.Saver(var_list = vars_to_save)\n",
    "                return tf.train.Scaffold()\n",
    "            \n",
    "        tf.logging.info('**** Trainable Variables ****')\n",
    "        for var in tvars:\n",
    "            init_string = ''\n",
    "            if var.name in initialized_variable_names:\n",
    "                init_string = ', *INIT_FROM_CKPT*'\n",
    "            tf.logging.info(' name = %s, shape = %s%s', var.name, var.shape, init_string)\n",
    "            \n",
    "            \n",
    "        return tf.contrib.tpu.TPUEstimatorSpec(\n",
    "            mode=mode,\n",
    "            loss=total_loss,\n",
    "            train_op=train_opt,\n",
    "            scaffold_fn=scaffold_fn\n",
    "        )\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_to_fixed_size(data, pad_value):\n",
    "  \n",
    "    output_shape = [35, 4]\n",
    "    max_num_instances = output_shape[0]\n",
    "    dimension = output_shape[1]\n",
    "    data = tf.reshape(data, [-1, dimension])\n",
    "    num_instances = tf.shape(data)[0]\n",
    "    assert_length = tf.Assert(\n",
    "      tf.less_equal(num_instances, max_num_instances), [num_instances])\n",
    "    with tf.control_dependencies([assert_length]):\n",
    "        pad_length = max_num_instances - num_instances\n",
    "    paddings = pad_value * tf.ones([pad_length, dimension])\n",
    "    padded_data = tf.concat([data, paddings], axis=0)\n",
    "    padded_data = tf.reshape(padded_data, output_shape)\n",
    "    return padded_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, true_boxes):\n",
    "    \n",
    "    tf.logging.info('preprocess')\n",
    "    hparams = get_hparams()\n",
    "    image = image/255.0\n",
    "    y_true_13, y_true_26, y_true_52 = tf.py_function(preprocess_true_boxes, inp=[true_boxes], Tout = [tf.float32, tf.float32, tf.float32])\n",
    "    \n",
    "    image = tf.reshape(image, [hparams.train_batch_size, hparams.width, hparams.height, hparams.channels])\n",
    "    \n",
    "    #y_true1_shape = y_true1.shape.as_list()\n",
    "    y_true1 = tf.reshape(y_true_13, [hparams.train_batch_size, 13, 13, 3, 6])\n",
    "    #y_true2_shape = y_true2.shape.as_list()\n",
    "    y_true2 = tf.reshape(y_true_26, [hparams.train_batch_size, 26, 26, 3, 6])\n",
    "    #y_true3_shape = y_true3.shape.as_list()\n",
    "    y_true3 = tf.reshape(y_true_52, [hparams.train_batch_size, 52, 52, 3, 6])\n",
    "    \n",
    "    labels = {}\n",
    "    labels['y_true1'] = y_true1\n",
    "    labels['y_true2'] = y_true2\n",
    "    labels['y_true3'] = y_true3\n",
    "    \n",
    "    #labels = [y_true1, y_true2, y_true3]\n",
    "    \n",
    "    return image, labels\n",
    "\n",
    "def preprocess_true_boxe(gt_boxes):\n",
    "    \"\"\"\n",
    "    Preprocess true boxes to training input format\n",
    "    Parameters:\n",
    "    -----------\n",
    "    :param true_boxes: numpy.ndarray of shape [T, 4]\n",
    "                        T: the number of boxes in each image.\n",
    "                        4: coordinate => x_min, y_min, x_max, y_max\n",
    "    :param true_labels: class id\n",
    "    :param input_shape: the shape of input image to the yolov3 network, [416, 416]\n",
    "    :param anchors: array, shape=[9,2], 9: the number of anchors, 2: width, height\n",
    "    :param num_classes: integer, for coco dataset, it is 80\n",
    "    Returns:\n",
    "    ----------\n",
    "    y_true: list(3 array), shape like yolo_outputs, [13, 13, 3, 85]\n",
    "                        13:cell szie, 3:number of anchors\n",
    "                        85: box_centers, box_sizes, confidence, probability\n",
    "    \"\"\"\n",
    "    tf.logging.info('preprocess_true_boxes')\n",
    "    hparams = get_hparams()\n",
    "    num_layers = len(hparams.anchors) // 3\n",
    "    anchor_mask = [[6,7,8], [3,4,5], [0,1,2]] if num_layers==3 else [[3,4,5], [1,2,3]]\n",
    "    grid_sizes = [[hparams.height//x, hparams.width//x] for x in (32, 16, 8)]\n",
    "    #print(gt_boxes.shape)\n",
    "    #print(gt_boxes[..., 0:2])\n",
    "\n",
    "    box_centers = (gt_boxes[:, 0:2] + gt_boxes[:, 2:4]) / 2 # the center of box\n",
    "    box_sizes =    gt_boxes[:, 2:4] - gt_boxes[:, 0:2] # the height and width of box\n",
    "\n",
    "    #gt_boxes[:, 0:2] = box_centers\n",
    "    #gt_boxes[:, 2:4] = box_sizes\n",
    "\n",
    "    y_true_13 = np.zeros(shape=[grid_sizes[0][0], grid_sizes[0][1], 3, 5+hparams.num_class], dtype=np.float32)\n",
    "    y_true_26 = np.zeros(shape=[grid_sizes[1][0], grid_sizes[1][1], 3, 5+hparams.num_class], dtype=np.float32)\n",
    "    y_true_52 = np.zeros(shape=[grid_sizes[2][0], grid_sizes[2][1], 3, 5+hparams.num_class], dtype=np.float32)\n",
    "\n",
    "    y_true = [y_true_13, y_true_26, y_true_52]\n",
    "    anchors_max =  hparams.anchors / 2.\n",
    "    anchors_min = -anchors_max\n",
    "    valid_mask = tf.greater(box_sizes[..., 0], 0)\n",
    "    valid_mask = tf.cast(valid_mask, dtype=tf.bool)\n",
    "\n",
    "    # Discard zero rows.\n",
    "    wh = tf.boolean_mask(box_sizes, valid_mask)\n",
    "    # set the center of all boxes as the origin of their coordinates\n",
    "    # and correct their coordinates\n",
    "    wh = np.expand_dims(wh, -2)\n",
    "    boxes_max = wh / 2.\n",
    "    boxes_min = -boxes_max\n",
    "\n",
    "    intersect_mins = tf.maximum(boxes_min, anchors_min)\n",
    "    intersect_maxs = tf.minimum(boxes_max, anchors_max)\n",
    "    intersect_wh   = tf.maximum(intersect_maxs - intersect_mins, 0.)\n",
    "    intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "    box_area       = wh[..., 0] * wh[..., 1]\n",
    "\n",
    "    anchor_area = hparams.anchors[:, 0] * hparams.anchors[:, 1]\n",
    "    iou = intersect_area / (box_area + anchor_area - intersect_area + 1e-10)\n",
    "    # Find best anchor for each true box\n",
    "    best_anchor = np.argmax(iou, axis=-1)\n",
    "\n",
    "    for t, n in enumerate(best_anchor):\n",
    "        #print(t)\n",
    "        for l in range(num_layers):\n",
    "            if n not in anchor_mask[l]: continue\n",
    "\n",
    "            i = np.floor(gt_boxes[t,0]/hparams.width*grid_sizes[l][1]).astype('int32')\n",
    "            j = np.floor(gt_boxes[t,1]/hparams.height*grid_sizes[l][0]).astype('int32')\n",
    "\n",
    "            k = anchor_mask[l].index(n)\n",
    "            c = 0\n",
    "\n",
    "            y_true[l][j, i, k, 0:2] = box_centers[t]\n",
    "            y_true[l][j, i, k, 2:4] = box_sizes[t]\n",
    "            y_true[l][j, i, k,   4] = 1.\n",
    "            y_true[l][j, i, k, 5+c] = 1.\n",
    "\n",
    "    return y_true_13, y_true_26, y_true_52\n",
    "\n",
    "\n",
    "def preprocess_true_boxes(true_boxes):\n",
    "    \n",
    "    tf.logging.info('preprocess_true_boxes')\n",
    "    hparams = get_hparams()\n",
    "    #true_boxes = np.array(true_boxes, dtype=np.float32)\n",
    "    input_shape = np.array(hparams.input_shape, dtype=np.int32)\n",
    "    num_layers = len(hparams.anchors)//3\n",
    "    anchor_mask = [[6,7,8], [3,4,5], [0,1,2]] if num_layers==3 else [[3,4,5], [1,2,3]]\n",
    "    grid_sizes = [input_shape//32, input_shape//16, input_shape//8]\n",
    "    \n",
    "    box_centers = (true_boxes[..., 0:2] + true_boxes[..., 2:4])//2\n",
    "    box_sizes = true_boxes[..., 2:4] - true_boxes[..., 0:2]\n",
    "    boxes_xy = box_centers\n",
    "    boxes_wh = box_sizes\n",
    "    #print(true_boxes)\n",
    "    #print(boxes_xy.shape)\n",
    "    #print(boxes_wh)\n",
    "    \n",
    "    mini_batch = true_boxes.shape[0]\n",
    "    #true_boxes[..., 0:2] = boxes_xy\n",
    "    #true_boxes[..., 2:4] = boxes_wh\n",
    "    #print(true_boxes)\n",
    "    #print(box_centers, box_sizes)\n",
    "    \n",
    "    y_true_13 = np.zeros(shape=[mini_batch, grid_sizes[0][0], grid_sizes[0][1], 3, 5+hparams.num_class], dtype=np.float32)\n",
    "    y_true_26 = np.zeros(shape=[mini_batch, grid_sizes[1][0], grid_sizes[1][1], 3, 5+hparams.num_class], dtype=np.float32)\n",
    "    y_true_52 = np.zeros(shape=[mini_batch, grid_sizes[2][0], grid_sizes[2][1], 3, 5+hparams.num_class], dtype=np.float32)\n",
    "        \n",
    "    \n",
    "    y_true=[y_true_13, y_true_26, y_true_52]\n",
    "    \n",
    "    anchors_max = hparams.anchors / 2\n",
    "    anchors_min = -anchors_max\n",
    "    valid_mask = box_sizes[..., 0] > 0\n",
    "    \n",
    "    for b in range(mini_batch):\n",
    "      \n",
    "      wh = box_sizes[b, valid_mask[b]]\n",
    "      if len(wh)==0: continue\n",
    "        \n",
    "      wh = np.expand_dims(wh, -2)\n",
    "     \n",
    "      boxes_max = wh / 2.\n",
    "      boxes_min = -boxes_max\n",
    "    \n",
    "      intersect_mins = np.maximum(boxes_min, anchors_min)\n",
    "      intersect_maxs = np.minimum(boxes_max, anchors_max)\n",
    "      intersect_wh = np.maximum(intersect_maxs - intersect_mins, 0.)\n",
    "      intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
    "      box_area = wh[..., 0] * wh[..., 1]\n",
    "    \n",
    "    \n",
    "      anchor_area = hparams.anchors[..., 0] * hparams.anchors[..., 1]\n",
    "      iou = intersect_area / (box_area + anchor_area - intersect_area + 1e-10)\n",
    "    \n",
    "      best_anchor = np.argmax(iou, axis=-1)\n",
    "      #print(best_anchor)\n",
    "\n",
    "      for t, n in enumerate(best_anchor):\n",
    "          #print(true_boxes[t, 0:4])\n",
    "          #print('\\n')\n",
    "          for l in range(num_layers):\n",
    "              if n in anchor_mask[l]:\n",
    "                \n",
    "                i = np.floor(true_boxes[b, t, 0]*grid_sizes[l][0]).astype('int32')\n",
    "                j = np.floor(true_boxes[b, t, 1]*grid_sizes[l][1]).astype('int32')\n",
    "                k = anchor_mask[l].index(n)\n",
    "                c = 0\n",
    "                y_true[l][b, i, j, k, 0:2] = boxes_xy[b, t, 0:2]\n",
    "                y_true[l][b, i, j, k, 2:4] = boxes_wh[b, t, 2:4]\n",
    "                y_true[l][b, i, j, k, 4] = 1\n",
    "                y_true[l][b, i, j, k, 5+c] = 1\n",
    "            \n",
    "    return y_true_13, y_true_26, y_true_52\n",
    "  \n",
    "    \n",
    "    \n",
    "def parse_data(feature):\n",
    "\n",
    "    tf.logging.info('parse_data')\n",
    "    features = tf.parse_single_example(\n",
    "        feature,\n",
    "        features={\n",
    "        'image': tf.FixedLenFeature([], tf.string),\n",
    "        'filename': tf.FixedLenFeature([], tf.string),\n",
    "        'height': tf.FixedLenFeature([], tf.int64),\n",
    "        'width': tf.FixedLenFeature([], tf.int64),\n",
    "        #'class_id': tf.VarLenFeature(tf.int64),\n",
    "        'objects': tf.FixedLenFeature([], tf.int64),\n",
    "        'bbox': tf.VarLenFeature(tf.float32)\n",
    "    })\n",
    "\n",
    "    objects = tf.cast(features['objects'], tf.int32)\n",
    "    #true_labels = tf.cast(features['class_id'].values, tf.int32)\n",
    "    width = tf.cast(features['width'], tf.int32)\n",
    "    height = tf.cast(features['height'], tf.int32)\n",
    "\n",
    "    image = tf.image.decode_jpeg(features['image'], channels=3)\n",
    "    shape = tf.stack([height, width, 3])\n",
    "\n",
    "    bbox = features['bbox']\n",
    "    bbox = tf.sparse.to_dense(bbox)\n",
    "    bbox = tf.reshape(bbox, [objects, 4])\n",
    "\n",
    "    #image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.reshape(image, shape)\n",
    "    #features['xmin'] = tf.cast(features['xmin'], tf.int32)\n",
    "    #print(features['xmin'])\n",
    "    image = tf.cast(image, dtype=tf.float32)\n",
    "    bbox = pad_to_fixed_size(bbox, 0)\n",
    "\n",
    "    #image = tf.image.convert\n",
    "    return preprocess(image, bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(params):\n",
    "    tf.logging.info('input_fn')\n",
    "    dataset = tf.data.TFRecordDataset(params['train_tfrecord'])\n",
    "    dataset = dataset.map(parse_data, num_parallel_calls=64)\n",
    "    #dataset = dataset.padded_batch(params['train_batch_size'], padded_shapes=([params['width'], params['height'], params['channels']], [None, 4]), drop_remainder=True)\n",
    "    dataset = dataset.batch(params['train_batch_size'], drop_remainder = True)\n",
    "    #dataset = dataset.map(preprocess, num_parallel_calls=64)\n",
    "    dataset = dataset.shuffle(params['shuffle'])\n",
    "    dataset = dataset.prefetch(tf.contrib.data.AUTOTUNE)\n",
    "    '''image, y_true1, y_true2, y_true3 = dataset.make_one_shot_iterator().get_next()\n",
    "    \n",
    "    image = tf.reshape(image, [params['train_batch_size'], params['width'], params['height'], params['channels']])\n",
    "    \n",
    "    #y_true1_shape = y_true1.shape.as_list()\n",
    "    y_true1 = tf.reshape(y_true1, [params['train_batch_size'], 13, 13, 3, 6])\n",
    "    #y_true2_shape = y_true2.shape.as_list()\n",
    "    y_true2 = tf.reshape(y_true2, [params['train_batch_size'], 26, 26, 3, 6])\n",
    "    #y_true3_shape = y_true3.shape.as_list()\n",
    "    y_true3 = tf.reshape(y_true3, [params['train_batch_size'], 52, 52, 3, 6])\n",
    "    \n",
    "    labels = {}\n",
    "    labels['y_true1'] = y_true1\n",
    "    labels['y_true2'] = y_true2\n",
    "    labels['y_true3'] = y_true3'''\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    hparams = get_hparams()\n",
    "    params = dict(\n",
    "        hparams.values(),\n",
    "        #train_batch_size= 32 * 8,\n",
    "        num_cores_per_replica = 1,\n",
    "        num_shards = 8\n",
    "    )\n",
    "    \n",
    "    num_train_steps = int(hparams.num_examples/hparams.train_batch_size * hparams.num_epochs)\n",
    "    \n",
    "    if params['use_tpu']:\n",
    "        tf.logging.info('Using TPU')\n",
    "        tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(\n",
    "            params['tpu'], zone=params['tpu_zone'], project=params['gcp_project']\n",
    "        )\n",
    "        tpu_grpc_url = tpu_cluster_resolver.get_master()\n",
    "        #tf.Session.reset(tpu_grpc_url)\n",
    "    else:\n",
    "        tpu_grpc_url = None\n",
    "        \n",
    "    \n",
    "    config_proto = tf.ConfigProto(\n",
    "        allow_soft_placement=True, log_device_placement=True\n",
    "    )\n",
    "    \n",
    "    tpu_config = tf.contrib.tpu.TPUConfig(\n",
    "        params['iteration_per_loop'],\n",
    "        num_shards = params['num_shards'],\n",
    "        per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n",
    "    )\n",
    "    \n",
    "    run_config = tf.contrib.tpu.RunConfig(\n",
    "        #master = tpu_grpc_url,\n",
    "        cluster = tpu_cluster_resolver,\n",
    "        save_summary_steps = 50,\n",
    "        save_checkpoints_steps = params['iteration_per_loop'],\n",
    "        model_dir = params['model_dir'],\n",
    "        session_config = config_proto,\n",
    "        tpu_config = tpu_config\n",
    "    )\n",
    "    \n",
    "    train_estimator = tf.contrib.tpu.TPUEstimator(\n",
    "        model_fn = model_fn,\n",
    "        model_dir = params['model_dir'],\n",
    "        use_tpu = params['use_tpu'],\n",
    "        train_batch_size = params['train_batch_size'],\n",
    "        config = run_config,\n",
    "        params = params\n",
    "    )\n",
    "    \n",
    "    tf.logging.info(\"***** Running training *****\")\n",
    "    tf.logging.info(\"  Num examples = %d\", hparams.num_examples)\n",
    "    tf.logging.info(\"  Batch size = %d\", hparams.train_batch_size)\n",
    "    tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
    "    \n",
    "    train_estimator.train(\n",
    "        input_fn = input_fn,\n",
    "        max_steps = num_train_steps\n",
    "    )\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
